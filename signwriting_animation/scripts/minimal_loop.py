# signwriting_animation/scripts/minimal_loop.py
import os
import math
from pathlib import Path
from typing import Dict, Tuple

import torch
import lightning as pl
from torch.utils.data import DataLoader
from pose_format.torch.masked.collator import zero_pad_collator

from signwriting_animation.data.data_loader import DynamicPosePredictionDataset
from signwriting_animation.diffusion.core.models import SignWritingToPoseDiffusion


# =====================
# dtype & utils
# =====================
def set_global_float32():
    torch.set_default_dtype(torch.float32)
    # è®©æ‰€æœ‰æ–°å»ºå¼ é‡é»˜è®¤ float32ï¼ˆé¿å… numpy -> double å¸¦æ¥çš„æ··ç”¨ï¼‰
    torch.set_default_tensor_type(torch.FloatTensor)


def btjc_to_bjct(x: torch.Tensor) -> torch.Tensor:
    """
    dataset è¾“å‡º: [B, T, J, C]  -> æ¨¡å‹æœŸæœ›: [B, J, C, T]
    å¹¶ç»Ÿä¸€æˆ float32 è¿ç»­å†…å­˜ã€‚
    """
    if x.ndim != 4:
        raise ValueError(f"Expected 4D tensor [B,T,J,C], got {x.shape} (ndim={x.ndim})")
    return x.permute(0, 2, 3, 1).contiguous().float()


def sanitize_btjc(x: torch.Tensor) -> torch.Tensor:
    """ç¡®ä¿æ˜¯ dense float32 è¿ç»­å†…å­˜ï¼ˆæœ‰äº›åœºæ™¯ä¼šè¿”å›ç¨€ç–/éè¿ç»­ Tensorï¼‰"""
    if x.is_sparse:
        x = x.to_dense()
    if x.dtype != torch.float32:
        x = x.float()
    if not x.is_contiguous():
        x = x.contiguous()
    return x


def masked_mse_btjc(pred_btjc: torch.Tensor, tgt_btjc: torch.Tensor, mask_bt: torch.Tensor) -> torch.Tensor:
    """
    pred/tgt: [B, T, J, C], mask: [B, T]  -> æœ‰æ•ˆå¸§ä¸Šçš„ MSE
    """
    pred_btjc = sanitize_btjc(pred_btjc)
    tgt_btjc = sanitize_btjc(tgt_btjc)
    mask_bt = mask_bt.float()

    diff2 = (pred_btjc - tgt_btjc) ** 2  # [B,T,J,C]
    m = mask_bt[:, :, None, None]        # [B,T,1,1]
    num = (diff2 * m).sum()
    den = (m.sum() * pred_btjc.size(2) * pred_btjc.size(3)).clamp_min(1.0)
    return num / den


def simple_dtw(a_td: torch.Tensor, b_td: torch.Tensor) -> torch.Tensor:
    """
    æœ´ç´  DTWï¼ˆCPUï¼Œä¸Šå°æ ·æœ¬ & ç‰‡æ®µå³å¯ï¼‰
    a/b: [T, D]
    """
    a = a_td.detach().cpu().float()
    b = b_td.detach().cpu().float()
    T, D = a.shape
    Tp, Dp = b.shape
    if D != Dp:
        raise ValueError(f"DTW feature dims mismatch: {D} vs {Dp}")

    dist = torch.cdist(a, b)  # [T, Tp]
    dp = torch.full((T + 1, Tp + 1), float("inf"))
    dp[0, 0] = 0.0
    for i in range(1, T + 1):
        for j in range(1, Tp + 1):
            cost = float(dist[i - 1, j - 1])
            dp[i, j] = cost + min(dp[i - 1, j], dp[i, j - 1], dp[i - 1, j - 1])
    return torch.tensor(dp[T, Tp], dtype=torch.float32)


def chunked_dtw_mean(btjc_pred: torch.Tensor, btjc_gt: torch.Tensor, mask_bt: torch.Tensor,
                     max_len: int = 160, chunk: int = 40) -> torch.Tensor:
    """
    æŠŠ [B,T,J,C] çš„ç¬¬ä¸€ä¸ªæ ·æœ¬æ‹‰ç›´æˆ [T,D]ï¼Œåšåˆ†ç‰‡ DTW å¹¶å¹³å‡ã€‚
    """
    b0 = 0
    T = int(mask_bt[b0].sum().item())
    T = min(T, btjc_pred.shape[1], max_len)
    if T <= 1:
        return torch.tensor(0.0)

    # [T, D] å…¶ä¸­ D = J*C
    pf_td = btjc_pred[b0, :T].reshape(T, -1)
    gt_td = btjc_gt[b0, :T].reshape(T, -1)

    vals = []
    for s in range(0, T, chunk):
        e = min(T, s + chunk)
        if e - s < 2:
            continue
        vals.append(simple_dtw(pf_td[s:e], gt_td[s:e]))
    return torch.stack(vals).mean() if vals else torch.tensor(0.0)


# =====================
# Data
# =====================
def make_loader(data_dir: str, csv_path: str, split: str,
                bs: int, num_past: int, num_future: int) -> DataLoader:
    ds = DynamicPosePredictionDataset(
        data_dir=data_dir,
        csv_path=csv_path,
        num_past_frames=num_past,
        num_future_frames=num_future,
        with_metadata=True,
        split=split,
    )
    return DataLoader(
        ds,
        batch_size=bs,
        shuffle=(split == "train"),
        num_workers=0,                 # å°æ‰¹é‡ + çœå†…å­˜
        pin_memory=False,
        persistent_workers=False,
        collate_fn=zero_pad_collator,
    )


# =====================
# Lightning Module
# =====================
class LitSWTDiffusion(pl.LightningModule):
    def __init__(self, num_keypoints: int, num_dims: int, lr: float = 1e-3):
        super().__init__()
        # ä½ çš„è‡ªå®šä¹‰æ¨¡å‹
        self.model = SignWritingToPoseDiffusion(
            num_keypoints=num_keypoints,
            num_dims_per_keypoint=num_dims
        )
        self.lr = lr

        # è¿è¡Œä¸­æ›²çº¿ç¼“å­˜ï¼ˆåŒæ—¶æˆ‘ä»¬ä¹Ÿä¼šå†™ CSVï¼‰
        self.train_loss_hist = []
        self.val_loss_hist = []
        self.val_dtw_hist = []

    def configure_optimizers(self):
        return torch.optim.AdamW(self.parameters(), lr=self.lr)

    def _forward_pose(self, fut_btjc: torch.Tensor, past_bjct: torch.Tensor, sign_b3hw: torch.Tensor) -> torch.Tensor:
        """
        ç”¨ä½ æ¨¡å‹çš„ interfaceï¼šè¾“å…¥:
          - x: æœªæ¥æ®µï¼ˆå™ªå£°/å ä½ï¼Œæœ€ç®€æˆ‘ä»¬ç›´æ¥ç”¨ GT å½¢çŠ¶çš„ 0 å¼ é‡ï¼‰
          - timesteps: è¿™é‡Œå…ˆç»™ 0ï¼ˆæœ€å°å¯è¿è¡Œç‰ˆæœ¬ï¼‰
          - y: dict é‡Œæ”¾ sign_image / input_poseï¼ˆæ³¨æ„å½¢çŠ¶ï¼‰
        è¾“å‡º:
          - é¢„æµ‹çš„æœªæ¥æ®µï¼ˆ[B,J,C,Tf]ï¼‰
        """
        B, T, J, C = fut_btjc.shape

        # æ¨¡å‹æœŸæœ›: x: [B,J,C,Tf]ï¼Œpast: [B,J,C,Tp]ï¼Œimage: [B,3,224,224]
        x_bjct = btjc_to_bjct(torch.zeros_like(fut_btjc))     # è¿™é‡Œç”¨ 0 å™ªå£°åšå ä½
        past_bjct = sanitize_btjc(past_bjct)
        sign_b3hw = sign_b3hw.float()

        timesteps = torch.zeros((B,), dtype=torch.long, device=x_bjct.device)
        y = {
            "sign_image": sign_b3hw,
            "input_pose": past_bjct,
        }
        pred_bjct = self.model.interface(x_bjct, timesteps, y)  # [B,J,C,Tf]
        # å›åˆ° [B,T,J,C]
        return pred_bjct.permute(0, 3, 1, 2).contiguous()

    def training_step(self, batch: Dict, _):
        # å–å‡º batch
        fut_btjc = sanitize_btjc(batch["data"])  # [B,Tf,J,C]
        cond = batch["conditions"]
        past_btjc = sanitize_btjc(cond["input_pose"])  # [B,Tp,J,C]
        # å˜æ¢ past -> [B,J,C,Tp]
        past_bjct = btjc_to_bjct(past_btjc)
        sign_b3hw = cond["sign_image"].float()  # [B,3,224,224]
        fut_mask_bt = cond["target_mask"].float()  # [B,Tf]

        # å‰å‘
        pred_btjc = self._forward_pose(fut_btjc, past_bjct, sign_b3hw)
        loss = masked_mse_btjc(pred_btjc, fut_btjc, fut_mask_bt)

        self.train_loss_hist.append(float(loss.detach().cpu()))
        self.log("train/loss", loss, prog_bar=True, on_step=True)
        return loss

    def validation_step(self, batch: Dict, _):
        fut_btjc = sanitize_btjc(batch["data"])
        cond = batch["conditions"]
        past_bjct = btjc_to_bjct(sanitize_btjc(cond["input_pose"]))
        sign_b3hw = cond["sign_image"].float()
        fut_mask_bt = cond["target_mask"].float()

        pred_btjc = self._forward_pose(fut_btjc, past_bjct, sign_b3hw)
        loss = masked_mse_btjc(pred_btjc, fut_btjc, fut_mask_bt)
        dtw = chunked_dtw_mean(pred_btjc, fut_btjc, fut_mask_bt, max_len=160, chunk=40)

        self.val_loss_hist.append(float(loss.detach().cpu()))
        self.val_dtw_hist.append(float(dtw.detach().cpu()))
        self.log("val/loss", loss, prog_bar=True)
        self.log("val/dtw", dtw, prog_bar=True)


# =====================
# CSV logger (ç®€å•æ˜“å–)
# =====================
class SimpleCSVLogger(pl.Callback):
    def __init__(self, csv_path: str):
        super().__init__()
        self.csv_path = Path(csv_path)
        self.csv_path.parent.mkdir(parents=True, exist_ok=True)
        # header
        if not self.csv_path.exists():
            self.csv_path.write_text("step,split,loss,dtw\n")

    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):
        step = trainer.global_step
        loss = float(pl_module.train_loss_hist[-1]) if pl_module.train_loss_hist else float("nan")
        with self.csv_path.open("a") as f:
            f.write(f"{step},train,{loss},\n")

    def on_validation_epoch_end(self, trainer, pl_module):
        step = trainer.global_step
        loss = pl_module.val_loss_hist[-1] if pl_module.val_loss_hist else float("nan")
        dtw = pl_module.val_dtw_hist[-1] if pl_module.val_dtw_hist else float("nan")
        with self.csv_path.open("a") as f:
            f.write(f"{step},val,{loss},{dtw}\n")


if __name__ == "__main__":
    set_global_float32()
    pl.seed_everything(42, workers=True)

    # --- è·¯å¾„ï¼šå¯ç”¨ç¯å¢ƒå˜é‡è¦†ç›– ---
    DATA_DIR = os.getenv("DATA_DIR", "/data/yayun/pose_data")  # ä½ çš„åŸå§‹ pose æ ¹ç›®å½•
    CSV_PATH = os.getenv("CSV_PATH", "/data/yayun/signwriting-animation/mini_data.csv")  # ä¹Ÿå¯åˆ‡ data.csv

    # --- å½¢çŠ¶å‚æ•°ï¼ˆä¸ä½ çš„æ•°æ®ä¿æŒä¸€è‡´ï¼‰---
    NUM_KEYPOINTS, NUM_DIMS = 586, 3
    NUM_PAST, NUM_FUTURE = 10, 5   # mini ç‰ˆæœ¬å…ˆå°çª—å£
    BATCH_SIZE = 1

    # --- dataloaders ---
    train_loader = make_loader(DATA_DIR, CSV_PATH, "train", BATCH_SIZE, NUM_PAST, NUM_FUTURE)
    # ç”¨ train é‡Œçš„åŒä¸€æ¡åš sanity-valï¼šå¦‚æœä½ æœ‰ dev splitï¼Œå»ºè®®åˆ‡æˆ dev
    val_loader = make_loader(DATA_DIR, CSV_PATH, "dev",   BATCH_SIZE, NUM_PAST, NUM_FUTURE)

    # --- æ¨¡å‹ & è®°å½• ---
    model = LitSWTDiffusion(num_keypoints=NUM_KEYPOINTS, num_dims=NUM_DIMS, lr=1e-3)
    csv_logger = SimpleCSVLogger(csv_path="logs/minimal_metrics.csv")

    # --- Trainer ---
    trainer = pl.Trainer(
        max_steps=int(os.getenv("MAX_STEPS", "600")),   # ä½ ä¹‹å‰ç”¨ 600ï¼Œå…ˆä¿æŒ
        accelerator="auto",
        devices=1,
        precision="32-true",    # ğŸ‘ˆ å¼ºåˆ¶å…¨ç¨‹ float32ï¼ˆæ›´ç¨³ï¼‰
        log_every_n_steps=5,
        enable_checkpointing=False,
        deterministic=True,
        callbacks=[csv_logger],
    )

    # --- å…ˆæ‹¿ä¸€æ‰¹åšå½¢çŠ¶æ£€æŸ¥ï¼ˆå¿«é€Ÿ fail fastï¼‰---
    try:
        bt = next(iter(train_loader))
        _ = bt["data"].shape
    except Exception as e:
        raise RuntimeError(f"First batch failed: {repr(e)}")

    # --- Train ---
    trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)

    print("\n[Done] Metrics CSV saved to: logs/minimal_metrics.csv")
    print("     Columns: step,split,loss,dtw")

