# -*- coding: utf-8 -*-
"""
å®Œå…¨ä¿®å¤ç‰ˆï¼š
1. ä¿®å¤ confidence shape (åŽ»æŽ‰å¤šä½™ç»´åº¦)
2. ä¿®å¤ FPS (ä½¿ç”¨ GT çš„ FPS)
3. ä¿ç•™è¿žç»­çš„ confidence å€¼
4. å¯¹æ¯”æ•°æ®èŒƒå›´
"""
import os
import torch
import numpy as np
import lightning as pl
from torch.utils.data import DataLoader

from pose_format import Pose
from pose_format.numpy.pose_body import NumPyPoseBody
from pose_format.utils.generic import reduce_holistic
from pose_format.torch.masked.collator import zero_pad_collator

from signwriting_animation.data.data_loader import DynamicPosePredictionDataset
from signwriting_animation.diffusion.lightning_module import LitMinimal, sanitize_btjc, masked_dtw


def tensor_to_pose_fixed(t_btjc, header, gt_body):
    """
    ä¿®å¤æ‰€æœ‰é—®é¢˜ï¼š
    1. Confidence shape æ­£ç¡® (3D ä¸æ˜¯ 4D)
    2. ä½¿ç”¨ GT çš„ FPS
    3. ä»Ž GT å­¦ä¹  confidence
    """
    if t_btjc.dim() == 4:
        t = t_btjc[0]
    elif t_btjc.dim() == 3:
        t = t_btjc
    else:
        raise ValueError(f"Expected 3D or 4D tensor, got {t_btjc.dim()}D")
    
    t_np = t.cpu().numpy().astype(np.float32)
    
    print(f"\n[tensor_to_pose_fixed] ä¿®å¤ç‰ˆ:")
    print(f"  PRED data shape: {t_np.shape}")
    print(f"  PRED data range: [{t_np.min():.4f}, {t_np.max():.4f}]")
    
    # arr: [T, 1, J, C]
    arr = t_np[:, None, :, :]
    
    # ðŸ”§ ä¿®å¤ 1: Confidence shape æ­£ç¡® - 3D ä¸æ˜¯ 4D
    # é”™è¯¯ï¼šconf = np.ones((arr.shape[0], 1, arr.shape[2], 1), ...)  # 4D
    # æ­£ç¡®ï¼šconf = np.ones((arr.shape[0], 1, arr.shape[2]), ...)     # 3D
    
    # ðŸ”§ ä¿®å¤ 2: ä»Ž GT å­¦ä¹  confidence çš„æ¨¡å¼
    # GT çš„å‰ 20 å¸§ confidence
    gt_conf_20 = gt_body.confidence[:20]  # shape: (20, 1, 178)
    
    print(f"\n  GT confidence (å‰20å¸§):")
    print(f"    shape: {gt_conf_20.shape}")
    print(f"    range: [{gt_conf_20.min():.4f}, {gt_conf_20.max():.4f}]")
    print(f"    å”¯ä¸€å€¼æ•°é‡: {len(np.unique(gt_conf_20))}")
    
    # ä½¿ç”¨ GT çš„ confidence
    conf = gt_conf_20.copy()
    
    print(f"\n  PRED confidence (ä½¿ç”¨GTçš„):")
    print(f"    shape: {conf.shape}")
    print(f"    =0: {(conf == 0).sum()} / {conf.size}")
    print(f"    =1: {(conf == 1).sum()} / {conf.size}")
    print(f"    (0,1): {((conf > 0) & (conf < 1)).sum()} / {conf.size}")
    
    # ðŸ”§ ä¿®å¤ 3: ä½¿ç”¨ GT çš„ FPS
    fps = gt_body.fps
    print(f"\n  ä½¿ç”¨ GT çš„ FPS: {fps}")
    
    body = NumPyPoseBody(fps=fps, data=arr, confidence=conf)
    
    print(f"\n  æœ€ç»ˆ body:")
    print(f"    fps: {body.fps}")
    print(f"    data shape: {body.data.shape}")
    print(f"    conf shape: {body.confidence.shape}")
    
    return Pose(header=header, body=body)


def analyze_data_range(gt_body, pred_tensor):
    """åˆ†æžæ•°æ®èŒƒå›´å·®å¼‚"""
    print(f"\n" + "="*70)
    print("æ•°æ®èŒƒå›´åˆ†æž")
    print("="*70)
    
    gt_data = gt_body.data
    pred_np = pred_tensor[0].cpu().numpy() if pred_tensor.dim() == 4 else pred_tensor.cpu().numpy()
    
    print(f"\n[GT (æ–‡ä»¶ä¸­)]")
    print(f"  shape: {gt_data.shape}")
    print(f"  range: [{gt_data.min():.4f}, {gt_data.max():.4f}]")
    print(f"  éžé›¶ range: [{gt_data[gt_data != 0].min():.4f}, {gt_data[gt_data != 0].max():.4f}]")
    
    print(f"\n[PRED (å½’ä¸€åŒ–ç©ºé—´)]")
    print(f"  shape: {pred_np.shape}")
    print(f"  range: [{pred_np.min():.4f}, {pred_np.max():.4f}]")
    
    print(f"\nâš ï¸ æ³¨æ„ï¼š")
    print(f"  GT æ–‡ä»¶ä¸­çš„æ•°æ®æ˜¯åŽŸå§‹åƒç´ åæ ‡ (range ~600)")
    print(f"  PRED æ˜¯å½’ä¸€åŒ–åŽçš„åæ ‡ (range ~2)")
    print(f"  è¿™æ˜¯æ­£å¸¸çš„ - æˆ‘ä»¬çš„ PRED å·²ç»ç»è¿‡ unnormalize")
    print(f"  ä½† unnormalize åŽçš„èŒƒå›´åº”è¯¥å’Œè®­ç»ƒæ—¶çš„ GT ä¸€è‡´")


if __name__ == "__main__":
    pl.seed_everything(42)

    data_dir = "/home/yayun/data/pose_data/"
    csv_path = "/home/yayun/data/signwriting-animation/data_fixed.csv"
    out_dir = "logs/minimal_178_fixed_all"
    os.makedirs(out_dir, exist_ok=True)

    stats_path = f"{data_dir}/mean_std_178_with_preprocess.pt"

    print("\n" + "="*70)
    print("å®Œå…¨ä¿®å¤ç‰ˆ")
    print("="*70 + "\n")

    # Dataset
    base_ds = DynamicPosePredictionDataset(
        data_dir=data_dir,
        csv_path=csv_path,
        num_past_frames=40,
        num_future_frames=20,
        with_metadata=True,
        split="train",
    )

    sample_0 = base_ds[0]
    
    class FixedSampleDataset(torch.utils.data.Dataset):
        def __init__(self, sample):
            self.sample = sample
        def __len__(self):
            return 1
        def __getitem__(self, idx):
            return self.sample
    
    train_ds = FixedSampleDataset(sample_0)
    train_loader = DataLoader(train_ds, batch_size=1, shuffle=False, collate_fn=zero_pad_collator)

    trainer = pl.Trainer(
        max_epochs=100,
        accelerator="gpu",
        devices=1,
        enable_checkpointing=False,
        log_every_n_steps=50,
    )

    num_joints = sample_0["data"].shape[-2]
    num_dims = sample_0["data"].shape[-1]

    model = LitMinimal(
        num_keypoints=num_joints,
        num_dims=num_dims,
        stats_path=stats_path,
        lr=1e-3,
        diffusion_steps=50,
        beta_start=1e-4,
        beta_end=2e-2,
        pred_target="x0",
    )

    trainer.fit(model, train_loader)

    # Inference
    print("\n" + "="*70)
    print("INFERENCE")
    print("="*70)

    model.eval()
    device = trainer.strategy.root_device
    model = model.to(device)

    with torch.no_grad():
        batch = next(iter(train_loader))
        cond = batch["conditions"]

        past = sanitize_btjc(cond["input_pose"][:1]).to(device)
        sign = cond["sign_image"][:1].float().to(device)
        gt = sanitize_btjc(batch["data"][:1]).to(device)

        future_len = gt.size(1)
        
        pred_norm = model.sample_autoregressive_fast(
            past_btjc=past,
            sign_img=sign,
            future_len=future_len,
            chunk=20,
        )

        pred = model.unnormalize(pred_norm)

        print(f"\nGT (è®­ç»ƒæ—¶):   [{gt.min():.4f}, {gt.max():.4f}]")
        print(f"PRED (ç”Ÿæˆ):   [{pred.min():.4f}, {pred.max():.4f}]")

        mask_bt = torch.ones(1, future_len, device=device)
        dtw_val = masked_dtw(pred, gt, mask_bt)
        print(f"DTW: {dtw_val:.4f}")

    # åŠ è½½ GT æ–‡ä»¶
    ref_path = base_ds.records[0]["pose"]
    ref_path = ref_path if os.path.isabs(ref_path) else os.path.join(data_dir, ref_path)

    with open(ref_path, "rb") as f:
        ref_pose = Pose.read(f)

    ref_reduced = reduce_holistic(ref_pose)
    ref_reduced = ref_reduced.remove_components(["POSE_WORLD_LANDMARKS"])
    header = ref_reduced.header

    gt_pose_obj = reduce_holistic(ref_pose)
    gt_pose_obj = gt_pose_obj.remove_components(["POSE_WORLD_LANDMARKS"])
    
    # åˆ†æžæ•°æ®èŒƒå›´
    analyze_data_range(gt_pose_obj.body, pred)

    # ä¿å­˜ GT
    out_gt = os.path.join(out_dir, "gt_final.pose")
    with open(out_gt, "wb") as f:
        gt_pose_obj.write(f)
    print(f"\nâœ“ GT ä¿å­˜: {out_gt}")

    # ä¿å­˜ PRED (å®Œå…¨ä¿®å¤)
    print("\n" + "="*70)
    print("ä¿å­˜ PRED (å®Œå…¨ä¿®å¤ç‰ˆ)")
    print("="*70)
    
    pose_pred = tensor_to_pose_fixed(pred, header, gt_pose_obj.body)
    out_pred = os.path.join(out_dir, "pred_fully_fixed.pose")
    with open(out_pred, "wb") as f:
        pose_pred.write(f)
    print(f"\nâœ“ PRED ä¿å­˜: {out_pred}")

    print("\n" + "="*70)
    print("âœ“ å®Œæˆï¼")
    print("="*70)
    print(f"\nç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"  1. GT:                {out_gt}")
    print(f"  2. PRED (å®Œå…¨ä¿®å¤):   {out_pred}")
    print(f"\nä¿®å¤å†…å®¹:")
    print(f"  âœ… Confidence shape: (20, 1, 178) - åŽ»æŽ‰å¤šä½™ç»´åº¦")
    print(f"  âœ… FPS: ä½¿ç”¨ GT çš„ {gt_pose_obj.body.fps}")
    print(f"  âœ… Confidence å€¼: ä½¿ç”¨ GT çš„è¿žç»­å€¼")
    print(f"\nåœ¨ sign.mt ä¸­æ‰“å¼€ pred_fully_fixed.pose")
    print(f"åº”è¯¥èƒ½æ­£å¸¸æ˜¾ç¤ºäº†ï¼")