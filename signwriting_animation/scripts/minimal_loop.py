# -*- coding: utf-8 -*-
import os
import torch
import numpy as np
import lightning as pl
from torch.utils.data import DataLoader

from pose_format import Pose
from pose_format.numpy.pose_body import NumPyPoseBody
from pose_format.utils.generic import reduce_holistic
from pose_format.torch.masked.collator import zero_pad_collator

from signwriting_animation.data.data_loader import DynamicPosePredictionDataset
from signwriting_animation.diffusion.lightning_module import LitMinimal, sanitize_btjc, masked_dtw

import signwriting_animation.diffusion.lightning_module as LM
print(">>> USING LIGHTNING MODULE FROM:", LM.__file__)



def tensor_to_pose(t_btjc, header):
    """
    Convert tensor â†’ Pose-format object.
    
    Args:
        t_btjc: Tensor of shape [B, T, J, C] or [T, J, C]
        header: Pose header
    
    Returns:
        Pose object
    """
    import numpy as np
    from pose_format.numpy.pose_body import NumPyPoseBody
    from pose_format import Pose
    
    # å¤„ç†ç»´åº¦
    if t_btjc.dim() == 4:
        # [B, T, J, C] -> [T, J, C]
        t = t_btjc[0]
    elif t_btjc.dim() == 3:
        # [T, J, C]
        t = t_btjc
    else:
        raise ValueError(f"Expected 3D or 4D tensor, got {t_btjc.dim()}D")
    
    print(f"  [tensor_to_pose] input shape: {t.shape}")  # åº”è¯¥æ˜¯ [T, J, C]
    
    # æ£€æµ‹é›¶ç‚¹
    zero_mask = (t.abs().sum(dim=-1) < 1e-6)
    num_zeros = zero_mask.sum().item()
    total = zero_mask.numel()
    print(f"  [tensor_to_pose] é›¶ç‚¹: {num_zeros}/{total} ({100*num_zeros/total:.1f}%)")
    
    # è½¬æ¢ä¸º numpy
    t_np = t.cpu().numpy().astype(np.float32)
    print(f"  [tensor_to_pose] numpy shape: {t_np.shape}")
    
    # æ£€æŸ¥æ•°æ®èŒƒå›´
    print(f"  [tensor_to_pose] æ•°æ®èŒƒå›´:")
    print(f"    X: [{t_np[:, :, 0].min():.4f}, {t_np[:, :, 0].max():.4f}]")
    print(f"    Y: [{t_np[:, :, 1].min():.4f}, {t_np[:, :, 1].max():.4f}]")
    print(f"    Z: [{t_np[:, :, 2].min():.4f}, {t_np[:, :, 2].max():.4f}]")
    
    # NumPyPoseBody æœŸæœ›çš„æ ¼å¼: [frames, people, points, dims]
    # æˆ‘ä»¬æœ‰: [frames, points, dims]
    # éœ€è¦æ·»åŠ  people ç»´åº¦
    arr = t_np[:, None, :, :]  # [T, 1, J, C]
    print(f"  [tensor_to_pose] arr shape after adding people dim: {arr.shape}")
    
    # ç½®ä¿¡åº¦
    conf = np.ones((arr.shape[0], 1, arr.shape[2], 1), dtype=np.float32)
    print(f"  [tensor_to_pose] conf shape: {conf.shape}")
    
    # åˆ›å»º body
    body = NumPyPoseBody(fps=25, data=arr, confidence=conf)
    
    # éªŒè¯
    print(f"  [tensor_to_pose] body.data.shape: {body.data.shape}")
    print(f"  [tensor_to_pose] ç¬¬ä¸€å¸§ç¬¬ä¸€ä¸ªç‚¹: {body.data[0, 0, 0]}")
    
    return Pose(header=header, body=body)


# ============================================================
# åœ¨ minimal_loop.py çš„ä¿å­˜éƒ¨åˆ†æ›¿æ¢
# ============================================================

print("\n[2] PRED:")

# ðŸ” ä¿å­˜å‰å†æ¬¡éªŒè¯
print(f"  pred shape: {pred.shape}")
print(f"  pred[0, 0, 0]: {pred[0, 0, 0]}")  # ç¬¬ä¸€å¸§ç¬¬ä¸€ä¸ªç‚¹
print(f"  pred[0, 0, 1]: {pred[0, 0, 1]}")  # ç¬¬ä¸€å¸§ç¬¬äºŒä¸ªç‚¹

pose_pred = tensor_to_pose(pred, header)

out_pred = os.path.join(out_dir, "pred_final.pose")
with open(out_pred, "wb") as f:
    pose_pred.write(f)

print(f"  ä¿å­˜åˆ°: {out_pred}")

# ðŸ” éªŒè¯ä¿å­˜åŽçš„æ–‡ä»¶
print(f"\n  éªŒè¯ä¿å­˜çš„æ–‡ä»¶:")
with open(out_pred, "rb") as f:
    verify_pose = Pose.read(f)

print(f"    è¯»å›žçš„ shape: {verify_pose.body.data.shape}")
print(f"    ç¬¬ä¸€å¸§ç¬¬ä¸€ä¸ªç‚¹: {verify_pose.body.data[0, 0, 0]}")
print(f"    æ•°æ®èŒƒå›´:")
print(f"      X: [{verify_pose.body.data[:, :, :, 0].min():.4f}, {verify_pose.body.data[:, :, :, 0].max():.4f}]")
print(f"      Y: [{verify_pose.body.data[:, :, :, 1].min():.4f}, {verify_pose.body.data[:, :, :, 1].max():.4f}]")
print(f"      Z: [{verify_pose.body.data[:, :, :, 2].min():.4f}, {verify_pose.body.data[:, :, :, 2].max():.4f}]")


if __name__ == "__main__":
    pl.seed_everything(42)

    data_dir = "/home/yayun/data/pose_data/"
    csv_path = "/home/yayun/data/signwriting-animation/data_fixed.csv"
    out_dir = "logs/minimal_178_fixed"
    os.makedirs(out_dir, exist_ok=True)

    stats_path = f"{data_dir}/mean_std_178_with_preprocess.pt"
    stats = torch.load(stats_path)

    print("\n" + "="*70)
    print("æœ€ç»ˆä¿®å¤ç‰ˆæœ¬")
    print("="*70)
    print("å½’ä¸€åŒ–ç­–ç•¥ï¼š")
    print("  - DataLoader: è¿”å›žåŽŸå§‹æ•°æ®ï¼ˆä¸å½’ä¸€åŒ–ï¼‰")
    print("  - LightningModule: ä½¿ç”¨å…¨å±€ç»Ÿè®¡é‡å½’ä¸€åŒ–")
    print("  - ç»“æžœ: åªå½’ä¸€åŒ–ä¸€æ¬¡ï¼Œé¿å…é‡å¤åŽ‹ç¼©")
    print("="*70 + "\n")

    # Dataset
    base_ds = DynamicPosePredictionDataset(
        data_dir=data_dir,
        csv_path=csv_path,
        num_past_frames=40,
        num_future_frames=20,
        with_metadata=True,
        split="train",
    )

    num_samples = min(200, len(base_ds))
    max_epochs = 20
    print(f"[INFO] è®­ç»ƒé…ç½®:")
    print(f"  - æ ·æœ¬æ•°: {num_samples} / {len(base_ds)}")
    print(f"  - Epochs: {max_epochs}")
    print(f"  - Batch size: 8")
    print(f"  - æ¯ä¸ªepoch: {num_samples // 8} batches")
    print(f"  - æ€»è®­ç»ƒæ­¥æ•°: {(num_samples // 8) * max_epochs}")
    print(f"  - é¢„è®¡æ—¶é—´: ~30-40 åˆ†é’Ÿ")
    print()

    train_indices = list(range(num_samples))
    train_ds = torch.utils.data.Subset(base_ds, train_indices)

    train_loader = DataLoader(
        train_ds,
        batch_size=8,
        shuffle=True,
        collate_fn=zero_pad_collator,
    )

    val_indices = list(range(num_samples, min(num_samples + 20, len(base_ds))))
    if len(val_indices) == 0:
        val_indices = list(range(max(0, num_samples - 20), num_samples))
    val_ds = torch.utils.data.Subset(base_ds, val_indices)
    val_loader = DataLoader(
        val_ds,
        batch_size=8,
        shuffle=False,
        collate_fn=zero_pad_collator,
    )

    print("\n" + "="*70)
    print("éªŒè¯ DataLoader è¾“å‡º")
    print("="*70)

    test_batch = next(iter(train_loader))
    test_data = test_batch["data"]
    test_data_dense = test_data.tensor if hasattr(test_data, "tensor") else test_data

    print(f"DataLoader è¾“å‡ºç»Ÿè®¡:")
    print(f"  Shape: {test_data_dense.shape}")
    print(f"  Min: {test_data_dense.min().item():.4f}")
    print(f"  Max: {test_data_dense.max().item():.4f}")
    print(f"  Mean: {test_data_dense.mean().item():.4f}")
    print(f"  Std: {test_data_dense.std().item():.4f}")

    if abs(test_data_dense.mean().item()) < 0.1 and abs(test_data_dense.std().item() - 1.0) < 0.2:
        print("\nâŒ é”™è¯¯ï¼šæ•°æ®å·²è¢«å½’ä¸€åŒ–ï¼")
        raise RuntimeError("DataLoader ä¸åº”è¯¥è¿”å›žå½’ä¸€åŒ–çš„æ•°æ®")
    else:
        print("\nâœ“ æ­£ç¡®ï¼šæ•°æ®æ˜¯åŽŸå§‹èŒƒå›´ï¼ˆæœªå½’ä¸€åŒ–ï¼‰")

    print("="*70 + "\n")

    num_joints = base_ds[0]["data"].shape[-2]
    num_dims = base_ds[0]["data"].shape[-1]
    print(f"[INFO] joints={num_joints}, dims={num_dims}")

    # Model
    model = LitMinimal(
        num_keypoints=num_joints,
        num_dims=num_dims,
        stats_path=stats_path,
        lr=5e-5,
        diffusion_steps=100,
    )

    trainer = pl.Trainer(
        max_epochs=max_epochs,
        accelerator="gpu" if torch.cuda.is_available() else "cpu",
        devices=1,
        enable_checkpointing=False,
        deterministic=False,
        log_every_n_steps=5,
    )

    print("\n[TRAIN] å¼€å§‹è®­ç»ƒ...")
    #trainer.fit(model, train_loader, val_loader)

    # ============================================================
    # Load header
    # ============================================================
    ref_path = base_ds.records[0]["pose"]
    ref_path = ref_path if os.path.isabs(ref_path) else os.path.join(data_dir, ref_path)

    with open(ref_path, "rb") as f:
        ref_pose = Pose.read(f)

    ref_reduced = reduce_holistic(ref_pose)
    ref_reduced = ref_reduced.remove_components(["POSE_WORLD_LANDMARKS"])
    header = ref_reduced.header

    print(f"\n[HEADER] total joints: {header.total_points()}")

    # ============================================================
    # Inference
    # ============================================================
    print("\n" + "="*70)
    print("INFERENCE - æœ€ç»ˆä¿®å¤ç‰ˆæœ¬")
    print("="*70)

    model.eval()
    device = trainer.strategy.root_device
    model = model.to(device)
    model.mean_pose = model.mean_pose.to(device)
    model.std_pose = model.std_pose.to(device)

    with torch.no_grad():
        print("\n[DEBUG] åˆ›å»º inference loader...")
        inference_loader = DataLoader(
            train_ds,
            batch_size=1,
            shuffle=False,
            collate_fn=zero_pad_collator,
        )
        
        batch = next(iter(inference_loader))
        cond = batch["conditions"]

        past = sanitize_btjc(cond["input_pose"][:1]).to(device)
        sign = cond["sign_image"][:1].float().to(device)
        gt = sanitize_btjc(batch["data"][:1]).to(device)

        future_len = gt.size(1)
        print(f"\n[1] åŸºæœ¬ä¿¡æ¯:")
        print(f"    future_len = {future_len}")
        print(f"    GT shape: {gt.shape}")
        
        print(f"\n[2] è¾“å…¥æ•°æ®èŒƒå›´æ£€æŸ¥:")
        print(f"    GT range: [{gt.min():.4f}, {gt.max():.4f}]")
        print(f"    GT mean: {gt.mean():.4f}")
        print(f"    GT std: {gt.std():.4f}")
        
        print(f"\n[2.1] GT ç¬¬ä¸€å¸§å‰ 5 ä¸ªå…³é”®ç‚¹:")
        gt_frame0 = gt[0, 0]
        for i in range(5):
            x, y, z = gt_frame0[i]
            print(f"      å…³é”®ç‚¹ {i}: x={x:.4f}, y={y:.4f}, z={z:.4f}")
        
        if abs(gt.mean().item()) < 0.1:
            print("    âŒ è¾“å…¥æ•°æ®å·²è¢«å½’ä¸€åŒ–ï¼")
        else:
            print("    âœ“ è¾“å…¥æ•°æ®æ˜¯åŽŸå§‹èŒƒå›´")

        # ç”Ÿæˆ PRED
        print(f"\n[3] ç”Ÿæˆ PRED:")
        pred_norm = model.sample_autoregressive_fast(
            past_btjc=past,
            sign_img=sign,
            future_len=future_len,
            chunk=20,
        )
        
        print(f"    pred_norm shape: {pred_norm.shape}")
        print(f"    pred_norm range: [{pred_norm.min():.4f}, {pred_norm.max():.4f}]")
        print(f"    pred_norm mean: {pred_norm.mean():.4f}")
        print(f"    pred_norm std: {pred_norm.std():.4f}")
        
        print(f"\n[3.1] pred_norm ç¬¬ä¸€å¸§å‰ 5 ä¸ªå…³é”®ç‚¹:")
        pred_norm_frame0 = pred_norm[0, 0]
        for i in range(5):
            x, y, z = pred_norm_frame0[i]
            print(f"      å…³é”®ç‚¹ {i}: x={x:.4f}, y={y:.4f}, z={z:.4f}")

        print(f"\n[4] åå½’ä¸€åŒ– PRED:")
        pred = model.unnormalize(pred_norm)
        
        print(f"    PRED range:")
        print(f"      X: [{pred[...,0].min():.4f}, {pred[...,0].max():.4f}]")
        print(f"      Y: [{pred[...,1].min():.4f}, {pred[...,1].max():.4f}]")
        print(f"      Z: [{pred[...,2].min():.4f}, {pred[...,2].max():.4f}]")
        
        print(f"\n    GT range (å¯¹æ¯”):")
        print(f"      X: [{gt[...,0].min():.4f}, {gt[...,0].max():.4f}]")
        print(f"      Y: [{gt[...,1].min():.4f}, {gt[...,1].max():.4f}]")
        print(f"      Z: [{gt[...,2].min():.4f}, {gt[...,2].max():.4f}]")
        
        print(f"\n[4.1] PRED ç¬¬ä¸€å¸§å‰ 5 ä¸ªå…³é”®ç‚¹:")
        pred_frame0 = pred[0, 0]
        for i in range(5):
            x, y, z = pred_frame0[i]
            print(f"      å…³é”®ç‚¹ {i}: x={x:.4f}, y={y:.4f}, z={z:.4f}")
        
        print(f"\n[4.2] GT ç¬¬ä¸€å¸§å‰ 5 ä¸ªå…³é”®ç‚¹ (å¯¹æ¯”):")
        for i in range(5):
            x, y, z = gt_frame0[i]
            print(f"      å…³é”®ç‚¹ {i}: x={x:.4f}, y={y:.4f}, z={z:.4f}")
        
        pred_x_range = pred[...,0].max() - pred[...,0].min()
        gt_x_range = gt[...,0].max() - gt[...,0].min()
        range_ratio = pred_x_range / gt_x_range
        
        print(f"\n    èŒƒå›´æ¯”çŽ‡ (PRED/GT): X={range_ratio:.4f}")
        if 0.5 < range_ratio < 2.0:
            print(f"    âœ“ PRED æ•°å€¼èŒƒå›´æ­£å¸¸")

        print(f"\n[4.3] å…³é”®ç‚¹å”¯ä¸€æ€§æ£€æŸ¥:")
        unique_points = torch.unique(pred_frame0, dim=0)
        print(f"    PRED å”¯ä¸€ç‚¹: {len(unique_points)} / {pred_frame0.shape[0]}")
        
        if len(unique_points) < 10:
            print(f"    âŒ å‡ ä¹Žæ‰€æœ‰ç‚¹éƒ½ä¸€æ ·ï¼")
        else:
            print(f"    âœ“ å…³é”®ç‚¹æœ‰å¤šæ ·æ€§")
        
        zero_mask = (pred_frame0.abs().sum(dim=-1) < 1e-6)
        num_zeros = zero_mask.sum().item()
        print(f"\n[4.4] é›¶ç‚¹: {num_zeros} / {pred_frame0.shape[0]}")

        mask_bt = torch.ones(1, future_len, device=device)
        dtw_val = masked_dtw(pred, gt, mask_bt)
        print(f"\n[5] DTW: {dtw_val:.4f}")

    print("="*70 + "\n")

    print("\n" + "="*70)
    print("å…³é”®ç‚¹åˆ†å¸ƒæ£€æŸ¥")
    print("="*70)

    groups = {
        "Pose": (0, 33),
        "å·¦æ‰‹": (33, 54),
        "å³æ‰‹": (54, 75),
        "é¢éƒ¨": (75, 178),
    }

    print("\nPRED:")
    for name, (start, end) in groups.items():
        points = pred_frame0[start:end]
        x_r = points[:, 0].max() - points[:, 0].min()
        y_r = points[:, 1].max() - points[:, 1].min()
        z_r = points[:, 2].max() - points[:, 2].min()
        print(f"  {name}: X={x_r:.4f}, Y={y_r:.4f}, Z={z_r:.4f}")

    print("\nGT:")
    for name, (start, end) in groups.items():
        points = gt_frame0[start:end]
        x_r = points[:, 0].max() - points[:, 0].min()
        y_r = points[:, 1].max() - points[:, 1].min()
        z_r = points[:, 2].max() - points[:, 2].min()
        print(f"  {name}: X={x_r:.4f}, Y={y_r:.4f}, Z={z_r:.4f}")

    print("="*70 + "\n")

    print("\n" + "="*70)
    print("ä¿å­˜æ–‡ä»¶")
    print("="*70)

    print("\n[1] GT:")
    gt_file_path = base_ds.records[0]["pose"]
    gt_file_path = gt_file_path if os.path.isabs(gt_file_path) else os.path.join(data_dir, gt_file_path)

    with open(gt_file_path, "rb") as f:
        gt_from_file = Pose.read(f)
    
    gt_pose_obj = reduce_holistic(gt_from_file)
    gt_pose_obj = gt_pose_obj.remove_components(["POSE_WORLD_LANDMARKS"])

    out_gt = os.path.join(out_dir, "gt_final.pose")
    with open(out_gt, "wb") as f:
        gt_pose_obj.write(f)

    print(f"  ä¿å­˜: {out_gt}")

    print("\n[2] PRED:")
    pose_pred = tensor_to_pose(pred, header)

    out_pred = os.path.join(out_dir, "pred_final.pose")
    with open(out_pred, "wb") as f:
        pose_pred.write(f)

    print(f"  ä¿å­˜: {out_pred}")

    print("\n" + "="*70)
    print("âœ“ å®Œæˆï¼")
    print("="*70)
    print(f"\nåœ¨ pose viewer ä¸­æ‰“å¼€:")
    print(f"  - GT:   {out_gt}")
    print(f"  - PRED: {out_pred}")