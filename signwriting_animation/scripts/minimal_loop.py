# -*- coding: utf-8 -*-
import os
import torch
import numpy as np
import lightning as pl
from torch.utils.data import DataLoader

from pose_format import Pose
from pose_format.numpy.pose_body import NumPyPoseBody
from pose_format.utils.generic import reduce_holistic
from pose_format.torch.masked.collator import zero_pad_collator

from signwriting_animation.data.data_loader import DynamicPosePredictionDataset
from signwriting_animation.diffusion.lightning_module import LitMinimal, sanitize_btjc, masked_dtw

import signwriting_animation.diffusion.lightning_module as LM
print(">>> USING LIGHTNING MODULE FROM:", LM.__file__)


def tensor_to_pose(t_btjc, header):
    """
    Convert tensor ‚Üí Pose-format object.
    
    Args:
        t_btjc: Tensor of shape [B, T, J, C] or [T, J, C]
        header: Pose header
    
    Returns:
        Pose object
    """
    import numpy as np
    from pose_format.numpy.pose_body import NumPyPoseBody
    from pose_format import Pose
    
    # Â§ÑÁêÜÁª¥Â∫¶
    if t_btjc.dim() == 4:
        t = t_btjc[0]
    elif t_btjc.dim() == 3:
        t = t_btjc
    else:
        raise ValueError(f"Expected 3D or 4D tensor, got {t_btjc.dim()}D")
    
    print(f"  [tensor_to_pose] input shape: {t.shape}")
    
    # Ê£ÄÊµãÈõ∂ÁÇπ
    zero_mask = (t.abs().sum(dim=-1) < 1e-6)
    num_zeros = zero_mask.sum().item()
    total = zero_mask.numel()
    print(f"  [tensor_to_pose] Èõ∂ÁÇπ: {num_zeros}/{total} ({100*num_zeros/total:.1f}%)")

    t_np = t.cpu().numpy().astype(np.float32)
    print(f"  [tensor_to_pose] numpy shape: {t_np.shape}")
    
    print(f"  [tensor_to_pose] ÂéüÂßãÊï∞ÊçÆËåÉÂõ¥:")
    print(f"    X: [{t_np[:, :, 0].min():.4f}, {t_np[:, :, 0].max():.4f}]")
    print(f"    Y: [{t_np[:, :, 1].min():.4f}, {t_np[:, :, 1].max():.4f}]")
    print(f"    Z: [{t_np[:, :, 2].min():.4f}, {t_np[:, :, 2].max():.4f}]")
    print(f"\n  [tensor_to_pose] Â∫îÁî®ÂùêÊ†áËΩ¥‰øÆÊ≠£...")
    print(f"    Êò†Â∞Ñ: X‚ÜêY, Y‚ÜêZ, Z‚ÜêX")
    
    t_np_fixed = np.stack([
        t_np[:, :, 1],  # Y ‚Üí Êñ∞ÁöÑ X (ËÆ©ÂÆÉÂèòÊàêÊñá‰ª∂ÁöÑ Y)
        t_np[:, :, 2],  # Z ‚Üí Êñ∞ÁöÑ Y (ËÆ©ÂÆÉÂèòÊàêÊñá‰ª∂ÁöÑ Z)
        t_np[:, :, 0]   # X ‚Üí Êñ∞ÁöÑ Z (ËÆ©ÂÆÉÂèòÊàêÊñá‰ª∂ÁöÑ X)
    ], axis=-1)
    t_np_fixed = np.stack([
        t_np[:, :, 1],
        t_np[:, :, 2],  # ÂéüZ ‚Üí ËæìÂÖ•Y ‚Üí Êñá‰ª∂Z ‚úì
        t_np[:, :, 0]   # ÂéüX ‚Üí ËæìÂÖ•Z ‚Üí Êñá‰ª∂X ‚úì
    ], axis=-1)
    
    print(f"  [tensor_to_pose] ‰øÆÊ≠£ÂêéÂ∞ÜËæìÂÖ• NumPyPoseBody:")
    print(f"    ËæìÂÖ• X: [{t_np_fixed[:, :, 0].min():.4f}, {t_np_fixed[:, :, 0].max():.4f}] (ÂéüY)")
    print(f"    ËæìÂÖ• Y: [{t_np_fixed[:, :, 1].min():.4f}, {t_np_fixed[:, :, 1].max():.4f}] (ÂéüZ)")
    print(f"    ËæìÂÖ• Z: [{t_np_fixed[:, :, 2].min():.4f}, {t_np_fixed[:, :, 2].max():.4f}] (ÂéüX)")
    print(f"  È¢ÑÊúüÊñá‰ª∂ÊúÄÁªà:")
    print(f"    Êñá‰ª∂ X: ÂéüX")
    print(f"    Êñá‰ª∂ Y: ÂéüY")
    print(f"    Êñá‰ª∂ Z: ÂéüZ")
    
    # NumPyPoseBody ÊúüÊúõ: [frames, people, points, dims]
    arr = t_np_fixed[:, None, :, :]  # [T, 1, J, C]
    print(f"  [tensor_to_pose] arr shape: {arr.shape}")
    
    conf = np.ones((arr.shape[0], 1, arr.shape[2], 1), dtype=np.float32)
    
    body = NumPyPoseBody(fps=25, data=arr, confidence=conf)

    print(f"  [tensor_to_pose] body.data.shape: {body.data.shape}")
    print(f"  [tensor_to_pose] Á¨¨‰∏ÄÂ∏ßÁ¨¨‰∏Ä‰∏™ÁÇπ: {body.data[0, 0, 0]}")
    
    return Pose(header=header, body=body)


if __name__ == "__main__":
    pl.seed_everything(42)

    data_dir = "/home/yayun/data/pose_data/"
    csv_path = "/home/yayun/data/signwriting-animation/data_fixed.csv"
    out_dir = "logs/minimal_178_fixed"
    os.makedirs(out_dir, exist_ok=True)

    stats_path = f"{data_dir}/mean_std_178_with_preprocess.pt"
    stats = torch.load(stats_path)

    print("\n" + "="*70)
    print("ÊúÄÁªà‰øÆÂ§çÁâàÊú¨")
    print("="*70)
    print("ÂΩí‰∏ÄÂåñÁ≠ñÁï•Ôºö")
    print("  - DataLoader: ËøîÂõûÂéüÂßãÊï∞ÊçÆÔºà‰∏çÂΩí‰∏ÄÂåñÔºâ")
    print("  - LightningModule: ‰ΩøÁî®ÂÖ®Â±ÄÁªüËÆ°ÈáèÂΩí‰∏ÄÂåñ")
    print("  - ÁªìÊûú: Âè™ÂΩí‰∏ÄÂåñ‰∏ÄÊ¨°ÔºåÈÅøÂÖçÈáçÂ§çÂéãÁº©")
    print("="*70 + "\n")

    # Dataset
    base_ds = DynamicPosePredictionDataset(
        data_dir=data_dir,
        csv_path=csv_path,
        num_past_frames=40,
        num_future_frames=20,
        with_metadata=True,
        split="train",
    )

    #num_samples = min(200, len(base_ds))
    #max_epochs = 20
    #print(f"[INFO] ËÆ≠ÁªÉÈÖçÁΩÆ:")
    #print(f"  - Ê†∑Êú¨Êï∞: {num_samples} / {len(base_ds)}")
    #print(f"  - Epochs: {max_epochs}")
    #print(f"  - Batch size: 8")
    #print()

    #train_indices = list(range(num_samples))
    #train_ds = torch.utils.data.Subset(base_ds, train_indices)

    # Overfit 
    train_ds = torch.utils.data.Subset(base_ds, [0])
    train_loader = DataLoader(
        train_ds,
        batch_size=1,
        shuffle=False,
        collate_fn=zero_pad_collator,
    )

    trainer = pl.Trainer(
        max_epochs=1000,
        accelerator="gpu" if torch.cuda.is_available() else "cpu",
        devices=1,
        enable_checkpointing=False,
        deterministic=False,
        log_every_n_steps=1,
        overfit_batches=1,
    )


    val_indices = list(range(num_samples, min(num_samples + 20, len(base_ds))))
    if len(val_indices) == 0:
        val_indices = list(range(max(0, num_samples - 20), num_samples))
    val_ds = torch.utils.data.Subset(base_ds, val_indices)
    val_loader = DataLoader(
        val_ds,
        batch_size=8,
        shuffle=False,
        collate_fn=zero_pad_collator,
    )

    print("\n" + "="*70)
    print("È™åËØÅ DataLoader ËæìÂá∫")
    print("="*70)

    test_batch = next(iter(train_loader))
    test_data = test_batch["data"]
    test_data_dense = test_data.tensor if hasattr(test_data, "tensor") else test_data

    print(f"DataLoader ËæìÂá∫ÁªüËÆ°:")
    print(f"  Shape: {test_data_dense.shape}")
    print(f"  Min: {test_data_dense.min().item():.4f}")
    print(f"  Max: {test_data_dense.max().item():.4f}")
    print(f"  Mean: {test_data_dense.mean().item():.4f}")
    print(f"  Std: {test_data_dense.std().item():.4f}")

    if abs(test_data_dense.mean().item()) < 0.1 and abs(test_data_dense.std().item() - 1.0) < 0.2:
        print("\n‚ùå ÈîôËØØÔºöÊï∞ÊçÆÂ∑≤Ë¢´ÂΩí‰∏ÄÂåñÔºÅ")
        raise RuntimeError("DataLoader ‰∏çÂ∫îËØ•ËøîÂõûÂΩí‰∏ÄÂåñÁöÑÊï∞ÊçÆ")
    else:
        print("\n‚úì Ê≠£Á°ÆÔºöÊï∞ÊçÆÊòØÂéüÂßãËåÉÂõ¥")

    print("="*70 + "\n")

    num_joints = base_ds[0]["data"].shape[-2]
    num_dims = base_ds[0]["data"].shape[-1]
    print(f"[INFO] joints={num_joints}, dims={num_dims}")

    # Model
    model = LitMinimal(
        num_keypoints=num_joints,
        num_dims=num_dims,
        stats_path=stats_path,
        lr=5e-5,
        diffusion_steps=100,
    )

    #print("\n[TRAIN] Ë∑≥ËøáËÆ≠ÁªÉÔºà‰ΩøÁî®Â∑≤ËÆ≠ÁªÉÁöÑÊ®°ÂûãÔºâ...")
    trainer.fit(model, train_loader)

    # ============================================================
    # Load header
    # ============================================================
    ref_path = base_ds.records[0]["pose"]
    ref_path = ref_path if os.path.isabs(ref_path) else os.path.join(data_dir, ref_path)

    with open(ref_path, "rb") as f:
        ref_pose = Pose.read(f)

    ref_reduced = reduce_holistic(ref_pose)
    ref_reduced = ref_reduced.remove_components(["POSE_WORLD_LANDMARKS"])
    header = ref_reduced.header

    print(f"\n[HEADER] total joints: {header.total_points()}")

    # ============================================================
    # Inference
    # ============================================================
    print("\n" + "="*70)
    print("INFERENCE - ÊúÄÁªà‰øÆÂ§çÁâàÊú¨")
    print("="*70)

    model.eval()
    device = trainer.strategy.root_device
    model = model.to(device)
    model.mean_pose = model.mean_pose.to(device)
    model.std_pose = model.std_pose.to(device)

    with torch.no_grad():
        print("\n[DEBUG] ÂàõÂª∫ inference loader...")
        inference_loader = DataLoader(
            train_ds,
            batch_size=1,
            shuffle=False,
            collate_fn=zero_pad_collator,
        )
        
        batch = next(iter(inference_loader))
        cond = batch["conditions"]

        past = sanitize_btjc(cond["input_pose"][:1]).to(device)
        sign = cond["sign_image"][:1].float().to(device)
        gt = sanitize_btjc(batch["data"][:1]).to(device)

        future_len = gt.size(1)
        print(f"\n[1] Âü∫Êú¨‰ø°ÊÅØ:")
        print(f"    future_len = {future_len}")
        print(f"    GT shape: {gt.shape}")
        
        print(f"\n[2] ËæìÂÖ•Êï∞ÊçÆËåÉÂõ¥Ê£ÄÊü•:")
        print(f"    GT range: [{gt.min():.4f}, {gt.max():.4f}]")
        print(f"    GT mean: {gt.mean():.4f}")
        
        print(f"\n[2.1] GT Á¨¨‰∏ÄÂ∏ßÂâç 5 ‰∏™ÂÖ≥ÈîÆÁÇπ:")
        gt_frame0 = gt[0, 0]
        for i in range(5):
            x, y, z = gt_frame0[i]
            print(f"      ÂÖ≥ÈîÆÁÇπ {i}: x={x:.4f}, y={y:.4f}, z={z:.4f}")

        # ÁîüÊàê PRED
        print(f"\n[3] ÁîüÊàê PRED:")
        pred_norm = model.sample_autoregressive_fast(
            past_btjc=past,
            sign_img=sign,
            future_len=future_len,
            chunk=20,
        )
        
        print(f"    pred_norm shape: {pred_norm.shape}")

        print(f"\n[4] ÂèçÂΩí‰∏ÄÂåñ PRED:")
        pred = model.unnormalize(pred_norm)
        
        print(f"    PRED range:")
        print(f"      X: [{pred[...,0].min():.4f}, {pred[...,0].max():.4f}]")
        print(f"      Y: [{pred[...,1].min():.4f}, {pred[...,1].max():.4f}]")
        print(f"      Z: [{pred[...,2].min():.4f}, {pred[...,2].max():.4f}]")
        
        print(f"\n[4.1] PRED Á¨¨‰∏ÄÂ∏ßÂâç 5 ‰∏™ÂÖ≥ÈîÆÁÇπ:")
        pred_frame0 = pred[0, 0]
        for i in range(5):
            x, y, z = pred_frame0[i]
            print(f"      ÂÖ≥ÈîÆÁÇπ {i}: x={x:.4f}, y={y:.4f}, z={z:.4f}")

        # DTW
        mask_bt = torch.ones(1, future_len, device=device)
        dtw_val = masked_dtw(pred, gt, mask_bt)
        print(f"\n[5] DTW: {dtw_val:.4f}")

    print("="*70 + "\n")

    # ============================================================
    # ‰øùÂ≠òÊñá‰ª∂
    # ============================================================
    print("\n" + "="*70)
    print("‰øùÂ≠òÊñá‰ª∂")
    print("="*70)

    print("\n[1] GT:")
    gt_file_path = base_ds.records[0]["pose"]
    gt_file_path = gt_file_path if os.path.isabs(gt_file_path) else os.path.join(data_dir, gt_file_path)

    with open(gt_file_path, "rb") as f:
        gt_from_file = Pose.read(f)
    
    gt_pose_obj = reduce_holistic(gt_from_file)
    gt_pose_obj = gt_pose_obj.remove_components(["POSE_WORLD_LANDMARKS"])

    out_gt = os.path.join(out_dir, "gt_final.pose")
    with open(out_gt, "wb") as f:
        gt_pose_obj.write(f)

    print(f"  ‰øùÂ≠ò: {out_gt}")

    # üîß ËøôÈáåÊâçË∞ÉÁî® tensor_to_pose
    print("\n[2] PRED:")
    
    # ‰øùÂ≠òÂâçÈ™åËØÅ
    print(f"  pred shape: {pred.shape}")
    print(f"  pred[0, 0, 0]: {pred[0, 0, 0]}")
    print(f"  pred[0, 0, 1]: {pred[0, 0, 1]}")
    
    pose_pred = tensor_to_pose(pred, header)

    out_pred = os.path.join(out_dir, "pred_final.pose")
    with open(out_pred, "wb") as f:
        pose_pred.write(f)

    print(f"  ‰øùÂ≠òÂà∞: {out_pred}")

    # È™åËØÅ‰øùÂ≠òÂêéÁöÑÊñá‰ª∂
    print(f"\n  È™åËØÅ‰øùÂ≠òÁöÑÊñá‰ª∂:")
    with open(out_pred, "rb") as f:
        verify_pose = Pose.read(f)

    print(f"    ËØªÂõûÁöÑ shape: {verify_pose.body.data.shape}")
    print(f"    Á¨¨‰∏ÄÂ∏ßÁ¨¨‰∏Ä‰∏™ÁÇπ: {verify_pose.body.data[0, 0, 0]}")
    print(f"    Êï∞ÊçÆËåÉÂõ¥:")
    print(f"      X: [{verify_pose.body.data[:, :, :, 0].min():.4f}, {verify_pose.body.data[:, :, :, 0].max():.4f}]")
    print(f"      Y: [{verify_pose.body.data[:, :, :, 1].min():.4f}, {verify_pose.body.data[:, :, :, 1].max():.4f}]")
    print(f"      Z: [{verify_pose.body.data[:, :, :, 2].min():.4f}, {verify_pose.body.data[:, :, :, 2].max():.4f}]")

    print("\n" + "="*70)
    print("‚úì ÂÆåÊàêÔºÅ")
    print("="*70)
    print(f"\nÂú® pose viewer ‰∏≠ÊâìÂºÄ:")
    print(f"  - GT:   {out_gt}")
    print(f"  - PRED: {out_pred}")