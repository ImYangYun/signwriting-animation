{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3VoIZ9OMUKVWZ/IqUNy55",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ImYangYun/signwriting-animation/blob/main/thesis_dataloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from pose_format import Pose\n",
        "\n",
        "class PosePredictionDataset(Dataset):\n",
        "    def __init__(self, data_dir, segmentation_csv, past_frames=40, future_frames=20, with_metadata=False):\n",
        "        self.data_dir = data_dir\n",
        "        self.with_metadata = with_metadata\n",
        "        self.past_frames = past_frames\n",
        "        self.future_frames = future_frames\n",
        "        self.samples = []\n",
        "\n",
        "        df = pd.read_csv(segmentation_csv)\n",
        "        for _, row in df.iterrows():\n",
        "            pose_file = row[\"pose\"]\n",
        "            sample_path = os.path.join(data_dir, \"raw_poses\", pose_file)\n",
        "            if not os.path.exists(sample_path):\n",
        "                continue\n",
        "            self.samples.append({\n",
        "                \"path\": sample_path,\n",
        "                \"id\": pose_file,\n",
        "                \"start\": int(row[\"start\"]),\n",
        "                \"end\": int(row[\"end\"])\n",
        "            })\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.samples[idx]\n",
        "        with open(item[\"path\"], \"rb\") as f:\n",
        "            pose = Pose.read(f.read())\n",
        "\n",
        "        data = pose.body.data.data\n",
        "        mask = pose.body.data.mask\n",
        "\n",
        "        clip = data[item[\"start\"]:item[\"end\"]]\n",
        "        clip_mask = mask[item[\"start\"]:item[\"end\"]]\n",
        "\n",
        "        input_pose = clip[:self.past_frames]\n",
        "        target_pose = clip[self.past_frames:]\n",
        "        input_mask = clip_mask[:self.past_frames]\n",
        "\n",
        "        result = {\n",
        "            \"input_pose\": torch.tensor(input_pose, dtype=torch.float32),\n",
        "            \"target_pose\": torch.tensor(target_pose, dtype=torch.float32),\n",
        "            \"mask\": torch.tensor(input_mask, dtype=torch.bool),\n",
        "            \"id\": item[\"id\"]\n",
        "        }\n",
        "\n",
        "        if self.with_metadata:\n",
        "            result[\"metadata\"] = {\n",
        "                \"total_frames\": item[\"end\"] - item[\"start\"]\n",
        "            }\n",
        "\n",
        "        return result\n",
        "\n",
        "def collate_pose_fn(batch):\n",
        "    input_poses = [item[\"input_pose\"] for item in batch]\n",
        "    target_poses = [item[\"target_pose\"] for item in batch]\n",
        "    masks = [item[\"mask\"] for item in batch]\n",
        "\n",
        "    input_padded = pad_sequence(input_poses, batch_first=True)\n",
        "    target_padded = pad_sequence(target_poses, batch_first=True)\n",
        "    mask_padded = pad_sequence(masks, batch_first=True)\n",
        "\n",
        "    return {\n",
        "        \"input_pose\": input_padded,\n",
        "        \"target_pose\": target_padded,\n",
        "        \"mask\": mask_padded,\n",
        "        \"id\": [item[\"id\"] for item in batch],\n",
        "        \"metadata\": [item.get(\"metadata\", {}) for item in batch]\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    data_dir = \"/scratch/yayun/pose_data\"\n",
        "    segmentation_csv = os.path.join(data_dir, \"data_segmentation.csv\")\n",
        "\n",
        "    dataset = PosePredictionDataset(data_dir, segmentation_csv, past_frames=40, future_frames=20, with_metadata=True)\n",
        "    loader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_pose_fn, num_workers=0)\n",
        "\n",
        "    for batch in loader:\n",
        "        print(\"Loaded batch\")\n",
        "        print(\"Input Pose:\", batch[\"input_pose\"].shape)\n",
        "        print(\"Target Pose:\", batch[\"target_pose\"].shape)\n",
        "        print(\"Mask:\", batch[\"mask\"].shape)\n",
        "        print(\"IDs:\", batch[\"id\"])\n",
        "        break\n"
      ],
      "metadata": {
        "id": "SSoYPoqmrpp_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}